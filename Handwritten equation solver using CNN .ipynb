{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f09b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4dc6cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '(', ')', '+', ',', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', 'A', 'alpha', 'ascii_124', 'b', 'beta', 'C', 'cos', 'd', 'Delta', 'div', 'e', 'exists', 'f', 'forall', 'forward_slash', 'G', 'gamma', 'geq', 'gt', 'H', 'i', 'in', 'infty', 'int', 'j', 'k', 'l', 'lambda', 'ldots', 'leq', 'lim', 'log', 'lt', 'M', 'mu', 'N', 'neq', 'o', 'p', 'phi', 'pi', 'pm', 'prime', 'q', 'R', 'rightarrow', 'S', 'sigma', 'sin', 'sqrt', 'sum', 'T', 'tan', 'theta', 'times', 'u', 'v', 'w', 'X', 'y', 'z', '[', ']', '{', '}']\n"
     ]
    }
   ],
   "source": [
    "# Display a list of folders in a directory with names corresponding to the characters they contain\n",
    "\n",
    "path = 'C:/Users/shubh/Downloads/data/extracted_images'\n",
    "\n",
    "simbols = os.listdir(path)\n",
    "print(simbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f53773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that will open all the images in the corresponding directory in turn, convert to gray, \n",
    "# resize to the specified size (this is not relevant for the proposed dataset, just to make the solution more universal) \n",
    "# and put the numeric representation in the list\n",
    "\n",
    "def load_simbol_images(folder, out_size=28, path=path):\n",
    "    folder = os.path.join(path, folder)\n",
    "    simbols=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        image = cv2.imread(os.path.join(folder,filename))\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "        img_erode = cv2.erode(thresh, np.ones((2, 2), np.uint8), iterations=1)\n",
    "        img_res = cv2.resize(img_erode, (out_size, out_size), interpolation=cv2.INTER_AREA)\n",
    "        _, img_res = cv2.threshold(img_res, 210, 255, cv2.THRESH_BINARY)\n",
    "        simbols.append(img_res)\n",
    "    return simbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the created function, read the images in all 27 selected folders one by one, placing the processed images in x \n",
    "# and the directory name in y. This will create a dataset for training the model\n",
    "\n",
    "x = np.empty((0, 28, 28), dtype=float)\n",
    "y = np.empty(0, dtype='S3')\n",
    "for simbol in simbols:\n",
    "    sim_arr = load_simbol_images(simbol)\n",
    "    x = np.append(x, sim_arr, axis=0)\n",
    "    for i in range(0, len(sim_arr)):\n",
    "        y = np.append(y, [simbol], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one more dimension to the x array, since the images are one-color, its size is 1\n",
    "# Perform image color inversion and normalization\n",
    "\n",
    "x = np.expand_dims(x, axis=3)\n",
    "x = 255-x\n",
    "x /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95095476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the character values of y using LabelEncoder to numeric values, and then to binary class matrix\n",
    "\n",
    "num_classes = len(simbols)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and validation samples in the ratio of 0.9 to 0.1\n",
    "# In order for the validation dataset to contain various variants of y, generate \n",
    "# a list of random numbers, which will be used as indexes\n",
    "\n",
    "test_sample = random.sample(range(0, len(y)), int(len(y) * 0.1))\n",
    "train_sample = list(set(range(len(y))) - set(test_sample))\n",
    "\n",
    "train_x = x[train_sample, :, :]\n",
    "train_y = y[train_sample]\n",
    "test_x = x[test_sample, :, :]\n",
    "test_y = y[test_sample]\n",
    "\n",
    "print('train_x size:', train_x.shape)\n",
    "print('train length:', train_x.shape[0])\n",
    "print('test length:', test_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compiling a Sequential model with two 2D convolution layers, Flatten and Dense layer. \n",
    "# Take categorical_crossentropy as a loss function and accuracy as a metric.\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on 15 epochs with a batch size of 250.\n",
    "\n",
    "hist = model.fit(train_x, train_y, batch_size = 250, epochs=15, verbose=0, validation_data=(test_x, test_y))\n",
    "#model.save('HESCNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8314fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model loss/metric\n",
    "\n",
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print('test loss:', round(score[0], 4))\n",
    "print('test accuracy:', round(score[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7871f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that will take an image as input, calculate the outer common contour of all characters in the image\n",
    "# and calculate the line of the middle of the image for further work with degrees\n",
    "\n",
    "def ymean(img, frame=10):\n",
    "    df = pd.DataFrame(columns=['x', 'y', 'w', 'h'])\n",
    "    \n",
    "    gray =cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _,thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n",
    "    # Get contours\n",
    "    contours,_ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for i in range(0, len(contours)):\n",
    "        x,y,w,h = cv2.boundingRect(contours[i])\n",
    "        df.loc[i] = [x,y,w,h]\n",
    "    H = df.h.max()\n",
    "    df = df[df.x != 0]\n",
    "    df['hy'] = df.h + df.y\n",
    "    minY = df.y.min() - frame if df.y.min() > frame else 0\n",
    "    maxY = df.hy.max() + frame if H - df.y.max() > frame else H\n",
    "    bsln = round((maxY - minY) / 2)\n",
    "    return bsln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7622fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that takes an image as input, determines the coordinates of the contours of each of the characters in \n",
    "# the image, changes the shape of the symbol canvas to square and changes the resize to 28x28, corresponding to the shape \n",
    "# of the model input. The position of the character is also determined to determine the degree or not and the order of the \n",
    "# characters. The function returns a list of tuples with the x-coordinate, the position of the character relative to the \n",
    "# baseline and the character itself.\n",
    "\n",
    "def simbol_extract(img, ymean, out_size=28, frame=10):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1)\n",
    "    # Get contours\n",
    "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    output = img.copy()\n",
    "\n",
    "    simbols = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if hierarchy[0][idx][3] == 0 and w * h > 400:\n",
    "            x, y, w, h = x - frame, y - frame, w + 2*frame, h + 2*frame # frame = 5 is indent  \n",
    "            cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n",
    "            simbol_crop = gray[y:y + h, x:x + w]\n",
    "            # Resize letter canvas to square\n",
    "            size_max = max(w, h)\n",
    "            simbol_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "            if w > h:\n",
    "                y_pos = size_max//2 - h//2\n",
    "                simbol_square[y_pos:y_pos + h, 0:w] = simbol_crop\n",
    "            elif w < h:\n",
    "                x_pos = size_max//2 - w//2\n",
    "                simbol_square[0:h, x_pos:x_pos + w] = simbol_crop\n",
    "            else:\n",
    "                simbol_square = simbol_crop\n",
    "            # Fix the position of the symbol relative to the middle line of the general contour\n",
    "            if y+h <= ymean:\n",
    "                pos = 1\n",
    "            elif y > ymean and (y + h) >= 1.8 * ymean:\n",
    "                pos = 2\n",
    "            elif y >= (0.4 * ymean) and (y + h) <= 1.6 * ymean:\n",
    "                pos = 3\n",
    "            else:\n",
    "                pos = 0\n",
    "            # Resize letter to 28x28 and add letter and its X-coordinate\n",
    "            img_res = cv2.resize(simbol_square, (out_size, out_size), interpolation=cv2.INTER_AREA)\n",
    "            _, img_res = cv2.threshold(img_res, 254, 255, cv2.THRESH_BINARY)\n",
    "            img_erode = cv2.erode(img_res, np.ones((1, 1), np.uint8), iterations=1)\n",
    "            simbols.append((x, pos, img_res))\n",
    "    # Sort array inplace by X-coordinate\n",
    "    simbols.sort(key=lambda x: x[0], reverse=False)\n",
    "    # Show sequentially each separate simbol defined by the contour\n",
    "    print(' ' * 15, 'Symbols defined by contours')\n",
    "    n = len(simbols)\n",
    "    fig, ax = plt.subplots(1, n, figsize=(5, 1))\n",
    "    for i in range(0, n):\n",
    "        ax[i].imshow(simbols[i][2], 'gray', origin='upper')\n",
    "    plt.show()  \n",
    "    return simbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c81f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that will in turn make a prediction for each of the characters in the image and recognize them, process the \n",
    "# sequence of characters recognized by the model, convert them into a mathematical function / equation and calculate the result\n",
    "\n",
    "def handwritten_solver(smbls):\n",
    "        \n",
    "    s = ''\n",
    "    # Labels indicating that a brackets is open\n",
    "    flag = 0\n",
    "    flag2 = 0\n",
    "    # Loop through all the simbols in the image one by one\n",
    "    k = len(smbls)\n",
    "    for i in range(0, k):\n",
    "        # Add two dimensions to the image array, perform image color inversion and normalization\n",
    "        x = smbls[i][2].astype('float32')\n",
    "        x = np.expand_dims(x, axis=2)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = 255-x\n",
    "        x /= 255\n",
    "        # Identifying symbol with a Model\n",
    "        prediction = model.predict(x, verbose = 0)\n",
    "        prediction = [np.argmax(prediction)]\n",
    "        prediction = encoder.inverse_transform(prediction)[0]\n",
    "        # Perform simbol interpretation with reduction to a format acceptable for eval\n",
    "        if prediction == 'mlp':\n",
    "            prediction = '*'\n",
    "        elif prediction == 'div':\n",
    "            prediction = '/'\n",
    "        elif prediction == ',' and simbols[i][1] == 2: # pos=2(below midline), defined in def simbol_extract\n",
    "            prediction = '.'\n",
    "        # the images of the characters 'div' and ','' are very similar, so if the condition above about the position \n",
    "        # of the character below the middle line is not met, we interpret it as '/'\n",
    "        elif prediction == ',': \n",
    "            prediction = '/'\n",
    "        # similarly, the images of the characters 'x' and 'mpl' are very similar, so if the condition of the position \n",
    "        # of the character in the range 0.2 - 0.8 of the general contour is met, interpret 'x' as '*'      \n",
    "        elif prediction == 'x' and simbols[i][1] == 3:\n",
    "            prediction = '*'\n",
    "        # Add a call to the math library for e, sin, tan, log\n",
    "        elif prediction == 'e':\n",
    "            prediction = 'math.' + prediction\n",
    "        elif prediction == 'sin' or prediction == 'tan':\n",
    "            prediction = 'math.' + prediction + '('\n",
    "            flag += 1\n",
    "        elif prediction == 'log':\n",
    "            prediction = 'math.' + prediction + '('\n",
    "            flag2 += 1\n",
    "        else:\n",
    "            pass  \n",
    "        # Add of the degree to the equation if the position of the symbol is above the midline\n",
    "        if i > 0 and simbols[i-1][1] != 1 and simbols[i][1] == 1:\n",
    "            s += '**' + prediction\n",
    "        # Refine symbol below midline\n",
    "        elif simbols[i][1] == 2:\n",
    "            prediction = '.'\n",
    "            s += prediction\n",
    "        # Add a closing bracket if the label is not-null for log, tan and sin arguments\n",
    "        elif flag != 0 and (prediction == '+' or prediction == '-' or prediction == '/' or prediction == '*'):\n",
    "            s += ')' + prediction\n",
    "            flag -= 1\n",
    "        elif flag2 != 0 and (prediction == '+' or prediction == '-' or prediction == '/' or prediction == '*'):\n",
    "            s += ', 10)' + prediction\n",
    "            flag2 -= 1\n",
    "        else:\n",
    "            s += prediction\n",
    "    # Add a closing bracket if the label is not-null\n",
    "    if flag != 0:\n",
    "        s += ')'\n",
    "        flag -= 1\n",
    "    elif flag2 !=0:\n",
    "        s += ', 10)'\n",
    "        flag2 -= 1\n",
    "    return s, eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9085d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result on formulas created in MS Paint\n",
    "\n",
    "path = 'C:/Users/shubh/Downloads/equation/'\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    \n",
    "    print(' ' * 30, 'Origin equation')\n",
    "    image = cv2.imread('equation/' + file)\n",
    "    plt.imshow(image, origin='upper')\n",
    "    plt.show()\n",
    "    \n",
    "    baseline = ymean(image)\n",
    "    simbols = simbol_extract(image, baseline)\n",
    "        \n",
    "    equation, res = handwritten_solver(simbols)\n",
    "    print('Results:\\n\\nequation:', equation)  \n",
    "    print('solution =', res)\n",
    "    print('-' * 75)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d7e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
